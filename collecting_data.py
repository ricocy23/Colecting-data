# -*- coding: utf-8 -*-
"""Collecting data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14Jwa4OTygYQHYDbb4XDVtnQTV-h3O5sJ
"""

import pandas as pd

url="/content/iris.data"
df=pd.read_csv(url)

df.head()

#menambahkan header
column_header=["sepal length","sepal width","petal length","petal_width","class"]
df.columns=column_header
df.head()

#Menyimpan dataframe ke csv pada local hardisk
from google.colab import files
df.to_csv('data-iris.csv',index=False)
files.download('data-iris.csv')

#Menyimpan dataframe ke csv pada google drive
# Connect Google Drive to Colab
from google.colab import drive
drive.mount('/content/gdrive')
# Create a variable to store the data path on your drive
path = './gdrive/My Drive/colab/'
df.to_csv(path+'Data-Iris.csv', index=False)

# mengakses dataset dari kaggle yang telah disimpan ke local storage google‚ê£drive
path = 'https://drive.google.com/file/d/10iEc-y06nXcQjnIEAKjwQGHpyJg2kx52/view?usp=sharing'
file_id=path.split('/')[-2]
url='https://drive.google.com/uc?id=' + file_id
dataset = pd.read_csv(url)
dataset.head()

! pip install -q kaggle
from google.colab import files
files.upload()

#membuat folder kaggle & mengcopy file kaggle.json tersebut ke directory kaggle
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/

#mengubah hak akses/permission file tokennya
! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets list

!kaggle datasets download -d ruchi798/data-science-job-salaries

!ls

#ekstrak dulu, karna bentuknya zip file
import zipfile
zip = zipfile.ZipFile('data-science-job-salaries.zip', 'r')
zip.extractall('files')
zip.close()

import pandas as pd
salaries=pd.read_csv('/content/files/ds_salaries.csv')
salaries.head()

from bs4 import BeautifulSoup
import requests

url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue'
page = requests.get(url)
soup = BeautifulSoup(page.text, 'html')

print(soup.prettify())

soup.find('table')

soup.find_all('table')[1]

soup.find('table', class_ = 'wikitable sortable')

table = soup.find_all('table')[1]

print(table)

world_titles = table.find_all('th')

world_titles

world_table_titles = [title.text.strip() for title in world_titles]
print(world_table_titles)

#simpan ke dataframe
import pandas as pd
df = pd.DataFrame(columns = world_table_titles)
df

column_data = table.find_all('tr')

for row in column_data[1:]:
    row_data = row.find_all('td')
    individual_row_data = [data.text.strip() for data in row_data]

    length = len(df)
    df.loc[length] = individual_row_data

df

#akan tersimpan di local storage
df.to_csv('Companies.csv', index = False)